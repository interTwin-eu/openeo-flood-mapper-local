[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Flood mapping with openEO",
    "section": "",
    "text": "Preface\nThis is a thematic module example that supports the development of digital twins within the interTwin project.\nOn this page we showcase openEOs standardization of remote sensing and Earth observation operations. We do this by translating the flood mapping algorithm as presented in Bauer-Marschallinger et al. (2022), and part of the GloFAS Global Flood Monitoring to the openEO syntax of the Python Client. This algorithm employs Sentinel-1 backscattered microwaves, so-called “sigma nought” or \\(\\sigma^0\\), to detect flooding. In this exercise we will replicate the case study of the above mentioned paper, the February 2018 flooding of the Greek region of Thessaly.\n\n\n\nSource: Copernicus Emergency Management Service\n\n\n\n\n\n\nBauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian Roth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang Wagner. 2022. “Satellite-Based Flood Mapping Through Bayesian Inference from a Sentinel-1 SAR Datacube.” Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html",
    "href": "notebooks/1_yeoda_dc.html",
    "title": "1  openEO local processing",
    "section": "",
    "text": "1.1 Setting-up a Python Session\nWe begin by loading openEO for local processing and some additional packages for transforming and viewing data.\nfrom datetime import datetime\nfrom pathlib import Path\nimport numpy as np\n\nfrom openeo_flood_mapper_local.view_flood_map import view_flood_map\n\nfrom openeo.local import LocalConnection\nfrom openeo.processes import ProcessBuilder, array_element, add, multiply, sin, cos, mask, exp, median\n\nDid not load machine learning processes due to missing dependencies: Install them like this: `pip install openeo-processes-dask[implementations, ml]`",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#data-sources",
    "href": "notebooks/1_yeoda_dc.html#data-sources",
    "title": "1  openEO local processing",
    "section": "1.2 Data Sources",
    "text": "1.2 Data Sources\nThe paths to the local data sources define the collections to be loaded in the next steps. In the case of a local openEO instance, we do this by just supplying the paths to the files required for the analysis.\n\nROOT_DATA = \"\"\nhparam_id = Path(f\"{ROOT_DATA}openEO_local/tuw_s1_harpar/S1_CSAR_IWGRDH/SIG0-HPAR/V0M2R3/EQUI7_EU020M/E054N006T3/D080.nc\")\nplia_id = Path(f\"{ROOT_DATA}openEO_local/s1_parameters/S1_CSAR_IWGRDH/PLIA-TAG/V01R03/EQUI7_EU020M/E054N006T3/PLIA-TAG-MEAN_20200101T000000_20201231T235959__D080_E054N006T3_EU020M_V01R03_S1IWGRDH.nc\")\nsig0_id = Path(f\"{ROOT_DATA}openEO_local/s1_parameters/S1_CSAR_IWGRDH/SIG0/V1M1R1/EQUI7_EU020M/E054N006T3/SIG0_20180228T043908__VV_D080_E054N006T3_EU020M_V1M1R1_S1AIWGRDH_TUWIEN.nc\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#connect-to-an-openeo-backend",
    "href": "notebooks/1_yeoda_dc.html#connect-to-an-openeo-backend",
    "title": "1  openEO local processing",
    "section": "1.3 Connect to an openEO Backend",
    "text": "1.3 Connect to an openEO Backend\nEstablish the local connection by supplying path(s) to root directories of the data source(s). This results in a connection object which is a critical aspect of collection discovery on the backend by openEO, where in this instance the backend is your own machine.\n\nlocal_connection = LocalConnection([\n    hparam_id.parent.as_posix(), \n    plia_id.parent.as_posix(), \n    sig0_id.parent.as_posix()\n])",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#load-collections",
    "href": "notebooks/1_yeoda_dc.html#load-collections",
    "title": "1  openEO local processing",
    "section": "1.4 Load Collections",
    "text": "1.4 Load Collections\nWe can then load the collections. This is done by using the method load_collection() and by using the collection ids as defined above.\n\nhparam_dc = local_connection.load_collection(str(hparam_id))\nplia_dc = local_connection.load_collection(str(plia_id))\nsig0_dc = local_connection.load_collection(str(sig0_id))",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#openeo-analysis",
    "href": "notebooks/1_yeoda_dc.html#openeo-analysis",
    "title": "1  openEO local processing",
    "section": "1.5 openEO Analysis",
    "text": "1.5 openEO Analysis\nopenEO supplies a set of conventional and EO-specific functions (or “processes” in openEO terminology) to work with EO data. In this example, we begin by defining functions that represent the flood mapping algorithm as defined in Bauer-Marschallinger et al. (2022), and by using standard openEO functions. The flood mapping algorithm extracts the following information: 1) the expected backscattering from water bodies, and 2) the expected backscatter intensity over land pixels given historical data. Hence, this function makes use of observations along both the spatial and temporal dimensions of the datacube.\nWe first define the function that extracts average backscatter intensity over water bodies and we name it water_backscatter(). This functions applies so-called openEO “band math”, which are basically mathematical computations on the bands of the datacube. In this case, the band of the incidence angle (degrees) of the retrieved backscatter signal is multiplied by a factor consisting of the slope plus an intercept from a linear model. This linear model describes the relationship between incidence angle and backscattering over water globally. Applying this linear model results in expected water back scattering. In a follow-up, we use a so-called reducer function, taking the mean of the band over the time dimension, after which, we rename this dimension “wbsc” of type band.\n\ndef water_backscatter(plia_dc):\n    return (plia_dc * -0.394181 + -4.142015).reduce_bands('mean'). \\\n        add_dimension('bands', 'wbsc', 'bands')\n\nWe can apply this function to the incidence angle datacube, as follows:\n\nwater_bsc_dc = water_backscatter(plia_dc)\nwater_bsc_dc\n\n\n    \n    \n        \n    \n    \n\n\nHere we can see the basic premise of openEO. The previous call did not actually perform the data processing it only generates a JSON representation of the processing graph. Only by calling execute() on this object, we can actually perform the processing, like so:\n\nwater_bsc_dc.execute()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (bands: 1, y: 1300, x: 930)&gt;\ndask.array&lt;broadcast_to, shape=(1, 1300, 930), dtype=float32, chunksize=(1, 1300, 930), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * x            (x) float64 5.661e+06 5.661e+06 5.661e+06 ... 5.68e+06 5.68e+06\n  * y            (y) float64 6.42e+05 6.42e+05 6.42e+05 ... 6.16e+05 6.16e+05\n    spatial_ref  int64 ...\n  * bands        (bands) &lt;U4 'wbsc'\nAttributes:\n    reduced_dimensions_min_values:  {'bands': 'PLIA'}xarray.DataArraybands: 1y: 1300x: 930dask.array&lt;chunksize=(1, 1300, 930), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n4.61 MiB\n4.61 MiB\n\n\nShape\n(1, 1300, 930)\n(1, 1300, 930)\n\n\nDask graph\n1 chunks in 8 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                         930 1300 1\n\n\n\n\nCoordinates: (4)x(x)float645.661e+06 5.661e+06 ... 5.68e+06array([5661410., 5661430., 5661450., ..., 5679950., 5679970., 5679990.])y(y)float646.42e+05 6.42e+05 ... 6.16e+05array([641990., 641970., 641950., ..., 616050., 616030., 616010.])spatial_ref()int64...crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]GeoTransform :5400000.0 20.0 0.0 900000.0 0.0 -20.0[1 values with dtype=int64]bands(bands)&lt;U4'wbsc'array(['wbsc'], dtype='&lt;U4')Indexes: (3)xPandasIndexPandasIndex(Index([5661410.0, 5661430.0, 5661450.0, 5661470.0, 5661490.0, 5661510.0,\n       5661530.0, 5661550.0, 5661570.0, 5661590.0,\n       ...\n       5679810.0, 5679830.0, 5679850.0, 5679870.0, 5679890.0, 5679910.0,\n       5679930.0, 5679950.0, 5679970.0, 5679990.0],\n      dtype='float64', name='x', length=930))yPandasIndexPandasIndex(Index([641990.0, 641970.0, 641950.0, 641930.0, 641910.0, 641890.0, 641870.0,\n       641850.0, 641830.0, 641810.0,\n       ...\n       616190.0, 616170.0, 616150.0, 616130.0, 616110.0, 616090.0, 616070.0,\n       616050.0, 616030.0, 616010.0],\n      dtype='float64', name='y', length=1300))bandsPandasIndexPandasIndex(Index(['wbsc'], dtype='object', name='bands'))Attributes: (1)reduced_dimensions_min_values :{'bands': 'PLIA'}\n\n\nWe define a second function to obtain expected backscattering over land pixels. In this case we will have to use historical Sentinel-1 data for each pixel to negate the effect of seasons on the sigma nought signal. Hence a so-called harmonic model is fitted. The following function harmonic_expected_backscatter() uses this harmonic model for estimations optimised to filter out seasonal signals.\n\ndef harmonic_expected_backscatter(data, dtime_str):\n    w = np.pi * 2 / 365\n    dt = datetime.strptime(dtime_str, \"%Y-%m-%d\")\n    t = dt.timetuple().tm_yday\n    wt = w * t\n\n    M0 = data.band('M0')\n    S1 = data.band('S1')\n    S2 = data.band('S2')\n    S3 = data.band('S3')\n    C1 = data.band('C1')\n    C2 = data.band('C2')\n    C3 = data.band('C3')\n    hm_c1 = (M0 + S1 * np.sin(wt)) + (C1 * np.cos(wt))\n    hm_c2 = ((hm_c1 + S2 * np.sin(2 * wt)) + C2 * np.cos(2 * wt))\n    hm_c3 = ((hm_c2 + S3 * np.sin(3 * wt)) + C3 * np.cos(3 * wt))\n    return hm_c3.add_dimension('bands', 'hbsc', 'bands')\n\nWe can now again apply this function to a datacube. For this operation we use the hparam_dc datacube defining the harmonic parameters of said model. These parameters together with the date of the flooding event generate the expected backscattering per land pixel.\n\nland_bsc_dc = harmonic_expected_backscatter(hparam_dc, '2018-02-01')\n\nSo far we have covered a couple of the core features of the openEO Python Client syntax. However, in all these cases, the shape of the datacube was not altered. In the following section we cover what to do when want to change shape through accumulation or reduction of input values.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#processes-with-child-callbacks",
    "href": "notebooks/1_yeoda_dc.html#processes-with-child-callbacks",
    "title": "1  openEO local processing",
    "section": "1.6 Processes with Child “callbacks”",
    "text": "1.6 Processes with Child “callbacks”\nNow we will define the last function, which calculates the probability of flooding with a Bayesian classification model. The output of this function tells if a pixel is flooded based on the previous defined expected land and water backscattering. The implementation of this function is, however, different from the previous functions, as it is applied to subsets of datacubes through the openEO function reduce_bands() and it thereby changes the shape of the input values. This family of functions, which also includes, e.g., apply(), reduce_dimension(), and aggregate_spatial(), are known as the “parent” functions. These parent functions invoke a subprocess on the datacube, so-called child “callbacks”.\nThe following function will be used as a child callback to calculate flooding probabilities. Note that the function requires the openEO helper object ProcessBuilder.\n\ndef bayesian_flood_decision(x: ProcessBuilder) -&gt; ProcessBuilder:\n    nf_std = 2.754041\n    sig0 = x.array_element(index=0)\n    std = x.array_element(index=1)\n    wbsc = x.array_element(index=2)\n    hbsc = x.array_element(index=3)\n\n    f_prob = (1.0 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * \\\n        (((sig0 - wbsc) / nf_std) ** 2))\n    nf_prob = (1.0 / (nf_std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * \\\n        (((sig0 - hbsc) / nf_std) ** 2))\n\n    evidence = (nf_prob * 0.5) + (f_prob * 0.5)\n    f_post_prob = (f_prob * 0.5) / evidence \n    nf_post_prob = (nf_prob * 0.5) / evidence \n\n    # flood if flood class has higher probability\n    return f_post_prob.gt(nf_post_prob)\n\nWe will use a child callback to reduce a datacube consisting of the expected backscatter over water, the expected backscattering over land and it’s standard deviation, and the sigma nought values to one new band comprising the flood classifications per pixel.\nFor this we will first have to load the standard deviations of the expected land backscattering for each pixel and the sigma nought values for the particular timeperiod of the expected flooding (February 2018).\n\nstd_dc = hparam_dc.band('STD').add_dimension('bands', 'std', 'bands')\nsig0_dc = sig0_dc.reduce_bands('mean').add_dimension('bands', 'sig0', 'bands')\n\nNow we can merge all these datacubes, like so:\n\ndecision_in = sig0_dc. \\\n    merge_cubes(std_dc). \\\n    merge_cubes(water_bsc_dc). \\\n    merge_cubes(land_bsc_dc). \\\n    merge_cubes(plia_dc)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#openeo-flood-mapping",
    "href": "notebooks/1_yeoda_dc.html#openeo-flood-mapping",
    "title": "1  openEO local processing",
    "section": "2.1 openEO Flood Mapping",
    "text": "2.1 openEO Flood Mapping\nWe can check the results of the openEO by executing the processing steps with execute() and by plotting the flood mapping classification.\n\nflood_decision = flood_dc.execute()\nview_flood_map(flood_decision[0])\n\n\n\n\nopenEO floodmap - no pre-processing\n\n\n\n\nBy comparing this figure with the original study (Bauer-Marschallinger et al. 2022), we see that the openEO workflow can perform the same operations. There are, however, some differences with the original flood mapping study. These differences relate to the absence of the low sensitivity masking and post-processing steps of the flood probabilities in the openEO workflow. A priori low sensitivity masking removes observations in which situations arise that cause insensitivity to flood conditions for physical, geometric, or sensor-side reasons. Whereas, post-processing removes e.g. the small patches of supposed flooded pixels scattered throughout the image also known as “speckles”. These speckles produce a more noisy picture in the openEO example.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#masking-of-low-sensitivity-pixels",
    "href": "notebooks/1_yeoda_dc.html#masking-of-low-sensitivity-pixels",
    "title": "1  openEO local processing",
    "section": "2.2 Masking of Low Sensitivity Pixels",
    "text": "2.2 Masking of Low Sensitivity Pixels\nWe continue by improving our flood map by filtering out observations that we expect to have low sensitivity to flooding based on a predefined set of criteria.\n\n2.2.1 Masking of Exceeding Incidence Angles\nFirstly we mask areas where the incidence angle exceeds the maximum tolerable range of \\(27\\degree\\) to \\(48\\degree\\). These larger than usual incidence angles are a result of the area’s topography as beams reflect from steep slopes.\n\nmask_ia = (flood_dc.band(\"PLIA\") &gt;= 27) * (flood_dc.band(\"PLIA\") &lt;= 48)\nflood_dc = flood_dc * mask_ia\n\nThis results in the following map:\n\n\n\n\n\nopenEO floodmap - masking exceeding incidence angles\n\n\n\n\n\n\n2.2.2 Identification of Conflicting Distributions\nWe remove values that have already low backscatter values during normal conditions and which do not represent water. Examples of such surfaces are highways, airstrips. salt panes, or arid sand and/or bedrock. Identification of such conflicting distribution is done by comparing the expected local land distribution (from the harmonic model) with those from the water distribution, if these cannot be distinguished from each other, the pixel is excluded.\n\nwater_bsc_threshold = decision_in.band(\"wbsc\") + 0.5 * 2.754041\nmask_conflict = decision_in.band(\"hbsc\") &gt; water_bsc_threshold\nflood_dc = flood_dc * mask_conflict\n\nExclusion of these conflicting distributions look as follows:\n\n\n\n\n\nopenEO floodmap - masking conflicting distributions + exceeding incidence angles\n\n\n\n\n\n\n2.2.3 Removal of Measurement Outliers\nExtreme backscatter values are yet another source of insensitivity to floods. These outliers are not properly represented by the Bayesian model probabilities.\n\nland_bsc_lower = flood_dc.band(\"hbsc\") - 3 * flood_dc.band(\"std\")\nland_bsc_upper = flood_dc.band(\"hbsc\") + 3 * flood_dc.band(\"std\")\nwater_bsc_upper = flood_dc.band(\"wbsc\") + 3 * 2.754041\n\nmask_land_outliers = (flood_dc.band(\"sig0\") &gt; land_bsc_lower) * (flood_dc.band(\"sig0\") &lt; land_bsc_upper)\nmask_water_outliers = flood_dc.band(\"sig0\") &lt; water_bsc_upper\nflood_dc = flood_dc * (mask_land_outliers | mask_water_outliers)\n\nAdding this to the prvious masking results in the following map:\n\n\n\n\n\nopenEO floodmap - masking extreme outliers + conflicting distributions + exceeding incidence angles\n\n\n\n\n\n\n2.2.4 Denial of High Uncertainty on Decision\nIn some cases the posterior distribution is ambiguous as it falls close to a 0.5 probability of flooding (i.e., a coin flip). This happens when the probability distributions for water and land backscattering overlap and/or the measured backscatter values falls exactly in the middle of the two distributions. Hence a cut-off of 0.2 is used to limit the potential of falls positive classifications.\n\nmask_uncertainty = flood_dc.band(\"dec\") &gt; 0.8\nflood_dc = flood_dc * mask_uncertainty\n\nThis results in the following floodmap.\n\n\n\n\n\nopenEO floodmap - masking high uncertainty classifications + extreme outliers + conflicting distributions + exceeding incidence angles",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/1_yeoda_dc.html#postprocessing",
    "href": "notebooks/1_yeoda_dc.html#postprocessing",
    "title": "1  openEO local processing",
    "section": "2.3 Postprocessing",
    "text": "2.3 Postprocessing\nThe following steps are designed to further improve the clarity of the floodmaps. These filters do not directly relate to prior knowledge on backscattering, but consists of contextual evidence that supports, or oppose, a flood classification.\n\n2.3.1 Removal of Speckles\nOne such filtering approach targets so-called speckles. These speckles are areas of one or a few pixels, and which are likely the result of the diversity of scattering surfaces at a sub-pixel level. In this approach it is argued that small, solitary flood surfaces are unlikely. Hence speckles are removed by applying a smoothing filter which consists of a rolling window median along the x and y-axis simultaneously.\nThis approach is realized in openEO with the parent function apply_neighborhood() with a window size of 3 by 3 pixels. The child process median is used to average the window’s values.\n\nflood_decision = flood_dc. \\\n    apply_neighborhood(\"median\", dict(x=-1, y=-1), dict(x=2, y=2)). \\\n    execute()\n\nThis results in a much clearer flood map, as shown below:\n\n\n/home/mschobbe/miniconda3/envs/openeo-flood-mapper-local/lib/python3.10/site-packages/dask/utils.py:73: RuntimeWarning: All-NaN slice encountered\n  return func(*args, **kwargs)\n\n\n\n\n\nopenEO floodmap - masking high uncertainty classifications + extreme outliers + conflicting distributions + exceeding incidence angles + majority filter\n\n\n\n\n\n\n\n\nBauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian Roth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang Wagner. 2022. “Satellite-Based Flood Mapping Through Bayesian Inference from a Sentinel-1 SAR Datacube.” Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>openEO local processing</span>"
    ]
  },
  {
    "objectID": "notebooks/2_eodc_dc.html",
    "href": "notebooks/2_eodc_dc.html",
    "title": "2  openEO remote processing",
    "section": "",
    "text": "2.1 Setting-up a Python session\nWe again begin by loading openEO and some additional packages.\nimport numpy as np\nimport xarray as xr\nfrom datetime import datetime\nimport os\n\nfrom openeo_flood_mapper_local.view_flood_map import view_flood_map\n\nimport openeo\nfrom openeo.processes import ProcessBuilder, array_element, add, multiply, sin, cos, mask, exp, median",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>openEO remote processing</span>"
    ]
  },
  {
    "objectID": "notebooks/2_eodc_dc.html#connect-to-the-eodc-openeo-backend",
    "href": "notebooks/2_eodc_dc.html#connect-to-the-eodc-openeo-backend",
    "title": "2  openEO remote processing",
    "section": "2.2 Connect to the EODC openEO Backend",
    "text": "2.2 Connect to the EODC openEO Backend\nEstablish a connection to the EODC backend with openeo.connect(). This results in a connection object which is a critical aspect of collection discovery on the backend by openEO.\n\nbackend = \"https://openeo.eodc.eu\" \nconnection = openeo.connect(backend)\nconnection.authenticate_oidc()\n\nAuthenticated using refresh token.\n\n\n&lt;Connection to 'https://openeo.eodc.eu/openeo/1.1.0/' with OidcBearerAuth&gt;",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>openEO remote processing</span>"
    ]
  },
  {
    "objectID": "notebooks/2_eodc_dc.html#load-collections-from-the-eodc",
    "href": "notebooks/2_eodc_dc.html#load-collections-from-the-eodc",
    "title": "2  openEO remote processing",
    "section": "2.3 Load Collections from the EODC",
    "text": "2.3 Load Collections from the EODC\nWe can first have a look at the metadata available at the EODC for the required collections (SENTINEL1_SIG0_20M, SENTINEL1_HPAR, and SENTINEL1_MPLIA), like so:\n\nconnection.collection_metadata(\"SENTINEL1_SIG0_20M\")\n\n\n    \n    \n        \n    \n    \n\n\nWe can then load the collections. This is done by using the method load_collection() and by using the collection ids as defined above. During collection loading we also do some initial filtering on the spatial and temporal extent. More importantly, we have to filter SENTINEL1_MPLIA and SENTINEL1_HPAR for the descending orbit “D080” to be able to calculate the correct reference backscatter signatures. So, we use the following criteria for filtering.\n\nspatial_extent = {\"west\": 21.93, \"south\": 39.47, \"east\": 22.23, \"north\": 39.64}\nsensing_date = [\"2018-02-28T04:00:00Z\", \"2018-02-28T05:00:00Z\"]\nprops = {\n   \"sat:orbit_state\": lambda x: openeo.processes.eq(x, \"descending\"),\n   \"sat:relative_orbit\": lambda x: openeo.processes.eq(x, 80)\n}\n\n\nsig0_dc = connection.load_collection(\n    \"SENTINEL1_SIG0_20M\",\n    spatial_extent = spatial_extent,\n    temporal_extent = sensing_date,\n    bands=[\"VV\"]\n). \\\n    mean_time()\n\n\nconnection.collection_metadata(\"SENTINEL1_HPAR\")\n\n\n    \n    \n        \n    \n    \n\n\n\nhparam_dc = connection.load_collection(\n    \"SENTINEL1_HPAR\",\n    spatial_extent = spatial_extent,\n    temporal_extent = \"2019\",\n    properties=props\n). \\\n    mean_time()\n\n/home/mschobbe/miniconda3/envs/openeo-flood-mapper-local/lib/python3.10/site-packages/openeo/rest/connection.py:1188: UserWarning: SENTINEL1_HPAR property filtering with properties that are undefined in the collection metadata (summaries): sat:orbit_state, sat:relative_orbit.\n  return DataCube.load_collection(\n\n\n\nconnection.collection_metadata(\"SENTINEL1_MPLIA\")\n\n\n    \n    \n        \n    \n    \n\n\n\nplia_dc = connection.load_collection(\n    \"SENTINEL1_MPLIA\",\n    spatial_extent = spatial_extent,\n    temporal_extent = [\"2020-01-01\", \"2020-12-31\"],\n    bands=[\"MPLIA\"],\n    properties=props\n). \\\n    mean_time()\n\n/home/mschobbe/miniconda3/envs/openeo-flood-mapper-local/lib/python3.10/site-packages/openeo/rest/connection.py:1188: UserWarning: SENTINEL1_MPLIA property filtering with properties that are undefined in the collection metadata (summaries): sat:orbit_state, sat:relative_orbit.\n  return DataCube.load_collection(",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>openEO remote processing</span>"
    ]
  },
  {
    "objectID": "notebooks/2_eodc_dc.html#openeo-analysis-at-the-eodc",
    "href": "notebooks/2_eodc_dc.html#openeo-analysis-at-the-eodc",
    "title": "2  openEO remote processing",
    "section": "2.4 openEO Analysis at the EODC",
    "text": "2.4 openEO Analysis at the EODC\nThe remainder of the worklfow is similar to the local processing with some minor differences associated to naming of the objects.\n\ndef water_backscatter(plia_dc):\n    return (plia_dc.band('MPLIA') * -0.394181 + -4.142015). \\\n        add_dimension('bands', 'wbsc', 'bands')\n\nHere we apply again the water_backscatter() function to the incidence angle datacube, as follows:\n\nwater_bsc_dc = water_backscatter(plia_dc)\nwater_bsc_dc\n\n\n    \n    \n        \n    \n    \n\n\nTo initiate the processing we create a batch job with the create_job() method. This performs the data processing based on the JSON representation of the processing graph. Only by submitting this job to the EODC backend, we can actually perform the processing, like so:\n\nwater_bsc_res = water_bsc_dc.save_result(format = \"NetCDF\")\nwater_bsc_job = water_bsc_res.create_job(title = \"water_bsc_greece_flood_2018_as_NetCDF_py\")\nwater_bsc_job.start_job()\n\nWe can then download the results.\n\nwater_bsc_job.download_result(\"data/watter_backscatter/example.nc\")\n\nAnd view the retrieved data.\n\nwater_bsc_dc = xr.open_dataset(\"data/watter_backscatter/example.nc\")\nwater_bsc_dc\n\nThe following code is a duplicate of the local flood mapping processing pipeline, where we define the harmonic model.\n\ndef harmonic_expected_backscatter(data, dtime_str):\n    w = np.pi * 2 / 365\n    dt = datetime.strptime(dtime_str, \"%Y-%m-%d\")\n    t = dt.timetuple().tm_yday\n    wt = w * t\n\n    M0 = data.band('M0')\n    S1 = data.band('S1')\n    S2 = data.band('S2')\n    S3 = data.band('S3')\n    C1 = data.band('C1')\n    C2 = data.band('C2')\n    C3 = data.band('C3')\n    hm_c1 = (M0 + S1 * np.sin(wt)) + (C1 * np.cos(wt))\n    hm_c2 = ((hm_c1 + S2 * np.sin(2 * wt)) + C2 * np.cos(2 * wt))\n    hm_c3 = ((hm_c2 + S3 * np.sin(3 * wt)) + C3 * np.cos(3 * wt))\n    return hm_c3.add_dimension('bands', 'hbsc', 'bands')\n\nPerform this function on the datacube for the time slice of the flooding event.\n\nland_bsc_dc = harmonic_expected_backscatter(hparam_dc, '2018-02-01')\n\nIn turn, we define the Bayesian classification model, as follows:\n\ndef bayesian_flood_decision(x: ProcessBuilder) -&gt; ProcessBuilder:\n    nf_std = 2.754041\n    sig0 = x.array_element(index=0)\n    std = x.array_element(index=1)\n    wbsc = x.array_element(index=2)\n    hbsc = x.array_element(index=3)\n\n    f_prob = (1.0 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * \\\n        (((sig0 - wbsc) / nf_std) ** 2))\n    nf_prob = (1.0 / (nf_std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * \\\n        (((sig0 - hbsc) / nf_std) ** 2))\n\n    evidence = (nf_prob * 0.5) + (f_prob * 0.5)\n    f_post_prob = (f_prob * 0.5) / evidence \n    nf_post_prob = (nf_prob * 0.5) / evidence \n\n    # flood if flood class has higher probability\n    return f_post_prob.gt(nf_post_prob)\n\nAnd then execute this on a combined data cube, as follows:\n\nstd_dc = hparam_dc.band('STD').add_dimension('bands', 'std', 'bands')\nsig0_dc = sig0_dc.reduce_bands('mean').add_dimension('bands', 'sig0', 'bands')\n\ndecision_in_dc = sig0_dc. \\\n    merge_cubes(std_dc). \\\n    merge_cubes(water_bsc_dc). \\\n    merge_cubes(land_bsc_dc) . \\\n    merge_cubes(plia_dc)\n\nflood_dc = decision_in_dc.reduce_bands(bayesian_flood_decision). \\\n    add_dimension('bands', 'dec', 'bands')\n\nflood_dc = flood_dc.merge_cubes(decision_in_dc)\n\nFinally, we can again proceed and send this processing pipeline of to the EODC.\n\nflood_res = flood_dc.save_result(format = \"NetCDF\")\nflood_job = flood_res.create_job(title = \"flood_greece_flood_2018_as_NetCDF_py\")\nflood_job.start_job()\n\nAnd retrieve the data, like so:\n\nflood_job.download_result(\"data/thessaly_floodmap.nc\")\n\nNow let’s have a look at the processing job performed at EODC.\n\nview_flood_map(xr.open_dataset(\"data/thessaly_floodmap.nc\").dec)\n\n\n\n\nopenEO floodmap - no pre-processing\n\n\n\n\nWe can than also again extend this pipeline to include the postprocessing steps.\n\nMasking of Exceeding Incidence Angles\n\n\nmask_ia = (flood_dc.band(\"MPLIA\") &gt;= 27) * (flood_dc.band(\"MPLIA\") &lt;= 48)\nflood_dc = flood_dc * mask_ia\n\n\n\nCode\nflood_res = flood_dc.save_result(format = \"NetCDF\")\nflood_job = flood_res.create_job(title = \"flood_greece_flood_2018_as_NetCDF_py\")\nflood_job.start_job()\n\n\n\n\nCode\nflood_job.download_result(\"data/thessaly_floodmap_plia.nc\")\n\n\n\n\n\n\n\nopenEO floodmap - masking exceeding incidence angles\n\n\n\n\n\nIdentification of Conflicting Distributions\n\n\nwater_bsc_threshold = flood_dc.band(\"wbsc\") + 0.5 * 2.754041\nmask_conflict = flood_dc.band(\"hbsc\") &gt; water_bsc_threshold\nflood_dc = flood_dc * mask_conflict\n\n\n\nCode\nflood_res = flood_dc.save_result(format = \"NetCDF\")\nflood_job = flood_res.create_job(title = \"flood_greece_flood_2018_as_NetCDF_py\")\nflood_job.start_job()\n\n\n\n\nCode\nflood_job.download_result(\"data/thessaly_floodmap_plia_distr.nc\")\n\n\n\n\n\n\n\nopenEO floodmap - masking conflicting distributions + exceeding incidence angles\n\n\n\n\n\nRemoval of Measurement Outliers\n\n\nland_bsc_lower = flood_dc.band(\"hbsc\") - 3 * flood_dc.band(\"std\")\nland_bsc_upper = flood_dc.band(\"hbsc\") + 3 * flood_dc.band(\"std\")\nwater_bsc_upper = flood_dc.band(\"wbsc\") + 3 * 2.754041\n\nmask_land_outliers = (flood_dc.band(\"sig0\") &gt; land_bsc_lower) * (flood_dc.band(\"sig0\") &lt; land_bsc_upper)\nmask_water_outliers = flood_dc.band(\"sig0\") &lt; water_bsc_upper\nflood_dc = flood_dc * (mask_land_outliers | mask_water_outliers)\n\n\n\nCode\nflood_res = flood_dc.save_result(format = \"NetCDF\")\nflood_job = flood_res.create_job(title = \"flood_greece_flood_2018_as_NetCDF_py\")\nflood_job.start_job()\n\n\n\n\nCode\nflood_job.download_result(\"data/thessaly_floodmap_plia_distr_out.nc\")\n\n\n\n\n\n\n\nopenEO floodmap - masking extreme outliers + conflicting distributions + exceeding incidence angles\n\n\n\n\n\nDenial of High Uncertainty on Decision\n\n\nmask_uncertainty = flood_dc.band(\"dec\") &gt; 0.8\nflood_dc = flood_dc * mask_uncertainty\n\n\n\nCode\nflood_res = flood_dc.save_result(format = \"NetCDF\")\nflood_job = flood_res.create_job(title = \"flood_greece_flood_2018_as_NetCDF_py\")\nflood_job.start_job()\n\n\n\n\nCode\nflood_job.download_result(\"data/thessaly_floodmap_plia_distr_out_den.nc\")\n\n\n\n\n\n\n\nopenEO floodmap - masking high uncertainty classifications + extreme outliers + conflicting distributions + exceeding incidence angles",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>openEO remote processing</span>"
    ]
  },
  {
    "objectID": "notebooks/references.html",
    "href": "notebooks/references.html",
    "title": "References",
    "section": "",
    "text": "Bauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian\nRoth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang\nWagner. 2022. “Satellite-Based Flood\nMapping Through Bayesian\nInference from a Sentinel-1 SAR\nDatacube.” Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.",
    "crumbs": [
      "References"
    ]
  }
]